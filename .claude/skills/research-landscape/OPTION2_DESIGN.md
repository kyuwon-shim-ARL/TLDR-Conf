# Option 2 Design: Conceptual Framework Auto-Generation

## ëª©í‘œ

ë…¼ë¬¸ landscapeë¥¼ **ë¬¸ì œ-í•´ê²° ê³„í†µë„**ë¡œ ìë™ ì¬êµ¬ì„±í•˜ì—¬ ì—°ì‚¬ë“¤ì„ ì´ frameworkì— ë§¤í•‘

### í˜„ì¬ (Option 1)
```
Session Landscape:
â”œâ”€â”€ Reviews (ë¦¬ë·° ë…¼ë¬¸ë“¤)
â”œâ”€â”€ Anchors (ê±°ì  ë…¼ë¬¸ë“¤)
â”œâ”€â”€ Trends (ìµœì‹  ë™í–¥)
â””â”€â”€ Speakers mapped to papers
```

### ëª©í‘œ (Option 2)
```
Conceptual Framework:
â”œâ”€â”€ 1. í•µì‹¬ ë¬¸ì œ (Core Problems)
â”‚   â”œâ”€â”€ ë¬¸ì œ 1.1: [ìë™ ì¶”ì¶œëœ ë¬¸ì œ ì •ì˜]
â”‚   â”‚   â”œâ”€â”€ ê´€ë ¨ anchor papers
â”‚   â”‚   â”œâ”€â”€ ì£¼ìš” ë…¼ìŸì  (review papers)
â”‚   â”‚   â””â”€â”€ ì„¸ì…˜ ë‚´ ì—°ì‚¬: A, B
â”‚   â””â”€â”€ ë¬¸ì œ 1.2: [ë˜ ë‹¤ë¥¸ ë¬¸ì œ]
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ 2. ì ‘ê·¼ ë°©ì‹ (Approaches)
â”‚   â”œâ”€â”€ ë°©ë²•ë¡  A: [ìë™ ì¶”ì¶œ]
â”‚   â”‚   â”œâ”€â”€ ì´ë¡ ì  ê¸°ì´ˆ (anchor papers)
â”‚   â”‚   â”œâ”€â”€ ìµœì‹  ë°œì „ (trends)
â”‚   â”‚   â””â”€â”€ ì„¸ì…˜ ë‚´ ì—°ì‚¬: C, D
â”‚   â””â”€â”€ ë°©ë²•ë¡  B: [ì‹¤í—˜ì  ì ‘ê·¼]
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ 3. í•œê³„ì  & ëŒíŒŒêµ¬ (Limitations & Breakthroughs)
â”‚   â””â”€â”€ Emerging concepts â†’ ì—°ì‚¬ E
â”‚
â””â”€â”€ 4. ë¯¸ë˜ ë°©í–¥ (Future Directions)
    â””â”€â”€ ...
```

---

## í•µì‹¬ ë„ì „ ê³¼ì œ

### 1. Concept Extraction (ê°œë… ì¶”ì¶œ)
**ë¬¸ì œ**: ë…¼ë¬¸ ì œëª©/ì´ˆë¡ì—ì„œ í•µì‹¬ ê°œë…ì„ ì–´ë–»ê²Œ ì¶”ì¶œí•  ê²ƒì¸ê°€?

**ì ‘ê·¼**:
- **Option A (Simple)**: OpenAlex concepts í™œìš©
  - ì¥ì : ì´ë¯¸ ë¶„ë¥˜ë¨, ë¹ ë¦„
  - ë‹¨ì : ë„ˆë¬´ broad (e.g., "Medicine", "Biology")

- **Option B (Advanced)**: Title/abstract keyword extraction
  - TF-IDFë¡œ ì¤‘ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
  - ì¥ì : ì„¸ë°€í•¨
  - ë‹¨ì : êµ¬í˜„ ë³µì¡, NLP í•„ìš”

- **Option C (Hybrid)**: OpenAlex concepts + keyword co-occurrence
  - ì¥ì : ê· í˜•
  - **ì¶”ì²œ**: ì´ ë°©ì‹ ì‚¬ìš©

### 2. Hierarchical Classification (ê³„ì¸µ ë¶„ë¥˜)
**ë¬¸ì œ**: ë…¼ë¬¸ì„ "ë¬¸ì œ / ë°©ë²• / í•œê³„" ì¹´í…Œê³ ë¦¬ë¡œ ì–´ë–»ê²Œ ìë™ ë¶„ë¥˜?

**ì ‘ê·¼**:
- **Rule-based heuristics** (title/abstract pattern matching):
  ```python
  if "challenge" in title or "problem" in abstract:
      category = "Problem"
  elif "approach" in title or "method" in abstract:
      category = "Approach"
  elif "limitation" in abstract or "future" in title:
      category = "Limitation"
  ```

- **Concept co-occurrence** (ê´€ë ¨ ë…¼ë¬¸ë¼ë¦¬ ê·¸ë£¹í™”):
  - Papers with similar concepts â†’ same cluster
  - Clusterì˜ ì£¼ìš” concept â†’ framework node

- **Citation patterns**:
  - Anchor papers (heavily cited) â†’ Foundational problems
  - Recent trends â†’ Emerging solutions
  - Bridge papers â†’ Cross-cutting approaches

### 3. Framework Structure Generation (ê³„í†µë„ êµ¬ì¡° ìƒì„±)
**ë¬¸ì œ**: ê³„ì¸µ êµ¬ì¡°ë¥¼ ì–´ë–»ê²Œ ìë™ìœ¼ë¡œ ë§Œë“¤ ê²ƒì¸ê°€?

**ì „ëµ**:

#### Level 1: Top-level categories (ê³ ì •)
```
1. í•µì‹¬ ë¬¸ì œ (Core Problems)
2. ì ‘ê·¼ ë°©ì‹ (Approaches)
3. í•œê³„ì  & ëŒíŒŒêµ¬ (Limitations & Breakthroughs)
4. ë¯¸ë˜ ë°©í–¥ (Future Directions)
```

#### Level 2: Sub-categories (ìë™ ìƒì„±)
- Concept clustering (K-means or hierarchical)
- Top N concepts â†’ sub-categories

#### Level 3: Individual papers
- ê° ë…¼ë¬¸ì„ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ sub-categoryì— ë°°ì¹˜

---

## êµ¬í˜„ ì „ëµ

### Phase 1: MVP (Simple Heuristics)

**Input**: Landscape from Option 1
```python
landscape = {
    'reviews': [...],
    'anchors': [...],
    'recent_trends': [...],
    'trend_clusters': {...}
}
```

**Processing**:
1. Extract top N concepts from all papers (N=10)
2. Classify papers into 4 top-level categories (rule-based)
3. Cluster papers by concept similarity (K-means)
4. Generate framework structure

**Output**: Conceptual framework
```python
framework = {
    'core_problems': [
        {
            'problem': "Granuloma formation mechanisms",
            'concepts': ['granuloma', 'inflammation'],
            'anchor_papers': [...],
            'review_papers': [...],
            'speakers': ['Speaker A', 'Speaker B']
        }
    ],
    'approaches': [...],
    'limitations': [...],
    'future_directions': [...]
}
```

### Phase 2: Enhanced (NLP + ML)

**Additional capabilities**:
- Abstract text analysis (TF-IDF)
- More sophisticated classification (not just rule-based)
- Concept relationship graph (A â†’ B â†’ C)

---

## ì•Œê³ ë¦¬ì¦˜ ìƒì„¸

### Algorithm 1: Concept Extraction

```python
def extract_key_concepts(papers, top_k=10):
    """
    Extract top K concepts from paper collection.

    Uses OpenAlex concepts + co-occurrence analysis.
    """
    # Step 1: Count concept frequencies
    concept_counts = Counter()
    for paper in papers:
        for concept in paper['concepts']:
            concept_counts[concept['display_name']] += concept['score']

    # Step 2: Get top K
    top_concepts = [c for c, _ in concept_counts.most_common(top_k)]

    # Step 3: Filter out too generic (optional)
    generic = ['Medicine', 'Biology', 'Chemistry']
    top_concepts = [c for c in top_concepts if c not in generic]

    return top_concepts
```

### Algorithm 2: Paper Classification

```python
def classify_paper(paper):
    """
    Classify paper into: Problem / Approach / Limitation / Future.

    Uses title + abstract heuristics.
    """
    title = paper.get('title', '').lower()
    abstract = paper.get('abstract', '').lower() if 'abstract' in paper else ''

    # Heuristic rules
    problem_keywords = ['challenge', 'problem', 'difficulty', 'issue']
    approach_keywords = ['approach', 'method', 'technique', 'strategy', 'therapy']
    limitation_keywords = ['limitation', 'drawback', 'weakness']
    future_keywords = ['future', 'perspective', 'outlook', 'emerging']

    # Score each category
    scores = {
        'problem': sum(kw in title or kw in abstract for kw in problem_keywords),
        'approach': sum(kw in title or kw in abstract for kw in approach_keywords),
        'limitation': sum(kw in title or kw in abstract for kw in limitation_keywords),
        'future': sum(kw in title or kw in abstract for kw in future_keywords)
    }

    # Default based on paper type
    if paper in anchors:  # Foundational â†’ Problem definition
        scores['problem'] += 2
    elif paper in recent_trends:  # Recent â†’ Approach or Future
        scores['approach'] += 1
        scores['future'] += 1

    # Return category with highest score
    return max(scores, key=scores.get)
```

### Algorithm 3: Concept Clustering

```python
def cluster_papers_by_concepts(papers, num_clusters=5):
    """
    Cluster papers using concept similarity.

    Uses Jaccard similarity on concepts.
    """
    # Build concept vectors for each paper
    all_concepts = set()
    for paper in papers:
        all_concepts.update(c['display_name'] for c in paper['concepts'])

    concept_list = list(all_concepts)

    # Create binary vectors (paper has concept or not)
    vectors = []
    for paper in papers:
        paper_concepts = {c['display_name'] for c in paper['concepts']}
        vector = [1 if c in paper_concepts else 0 for c in concept_list]
        vectors.append(vector)

    # K-means clustering
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    labels = kmeans.fit_predict(vectors)

    # Group papers by cluster
    clusters = {}
    for i, label in enumerate(labels):
        if label not in clusters:
            clusters[label] = []
        clusters[label].append(papers[i])

    # Name each cluster by top concepts
    cluster_names = {}
    for label, cluster_papers in clusters.items():
        concept_counts = Counter()
        for paper in cluster_papers:
            for concept in paper['concepts']:
                concept_counts[concept['display_name']] += 1

        # Top 2 concepts as cluster name
        top_2 = [c for c, _ in concept_counts.most_common(2)]
        cluster_names[label] = ' & '.join(top_2)

    return clusters, cluster_names
```

### Algorithm 4: Framework Generation

```python
def generate_conceptual_framework(landscape, speakers=None):
    """
    Generate problem-solution framework from landscape.
    """
    framework = {
        'core_problems': [],
        'approaches': [],
        'limitations': [],
        'future_directions': []
    }

    all_papers = landscape['reviews'] + landscape['anchors'] + landscape.get('recent_trends', [])

    # Step 1: Extract key concepts
    key_concepts = extract_key_concepts(all_papers, top_k=10)

    # Step 2: Classify each paper
    classified = {
        'problem': [],
        'approach': [],
        'limitation': [],
        'future': []
    }

    for paper in all_papers:
        category = classify_paper(paper)
        classified[category].append(paper)

    # Step 3: Cluster within each category
    for category, papers in classified.items():
        if not papers:
            continue

        if len(papers) >= 3:  # Only cluster if enough papers
            clusters, names = cluster_papers_by_concepts(papers, num_clusters=min(3, len(papers)//2))

            for label, cluster_papers in clusters.items():
                node = {
                    'name': names[label],
                    'papers': cluster_papers,
                    'speakers': []  # Will be filled if speaker mapping provided
                }
                framework[category + 's'].append(node)
        else:
            # Too few papers, just group all
            node = {
                'name': key_concepts[0] if key_concepts else category.title(),
                'papers': papers,
                'speakers': []
            }
            framework[category + 's'].append(node)

    # Step 4: Map speakers (if provided)
    if speakers:
        for speaker in speakers:
            # Find best matching node based on speaker's research areas
            # (implementation omitted for brevity)
            pass

    return framework
```

---

## ì¶œë ¥ í˜•ì‹

### Markdown Output Example

```markdown
## ğŸ”¬ ê°œë…ì  Research Framework: Mycobacterial Pathogenesis

*ìë™ ìƒì„±ëœ ë¬¸ì œ-í•´ê²° ê³„í†µë„*

### 1. í•µì‹¬ ë¬¸ì œ (Core Problems)

#### 1.1 Granuloma Formation & Immune Evasion

**ë¬¸ì œ ì •ì˜**: How do mycobacteria establish persistent infections through granuloma manipulation?

**ê±°ì  ë…¼ë¬¸** (ì´ë¡ ì  ê¸°ì´ˆ):
1. "Histopathologic review of granulomatous inflammation" (2017, 323 cites)
2. "Neutrophils in granulomas" (2019, 109 cites)

**ì£¼ìš” ë…¼ìŸì ** (ë¦¬ë·° ë…¼ë¬¸):
- Balance between containment and pathology
- Role of neutrophils vs macrophages

**ì„¸ì…˜ ë‚´ ì—°ì‚¬**:
- **Speaker A (Neutrophil Role)**: Addresses neutrophil function in granuloma maintenance
  - Related to: Anchor paper #2
  - Position: Investigates cellular mechanisms

#### 1.2 Drug Resistance Mechanisms

**ë¬¸ì œ ì •ì˜**: Mechanisms of antibiotic resistance and persistence

**ê±°ì  ë…¼ë¬¸**:
1. "Oxidative phosphorylation as drug target" (2017, 120 cites)

**ì„¸ì…˜ ë‚´ ì—°ì‚¬**:
- **Speaker C (Drug Targets)**: Novel targets for overcoming resistance
  - Related to: Trend cluster "Mycobacterium abscessus"

---

### 2. ì ‘ê·¼ ë°©ì‹ (Approaches)

#### 2.1 Host-Directed Therapy

**ë°©ë²•ë¡ **: Modulating host immune response rather than targeting pathogen

**ì´ë¡ ì  ê¸°ì´ˆ**:
- "Host-directed therapies for TB" (2015, 113 cites)

**ìµœì‹  ë°œì „** (2023-2025):
- Immunomodulation approaches (18 papers)
- Autophagy induction (12 papers)

**ì„¸ì…˜ ë‚´ ì—°ì‚¬**:
- **Speaker B (Host-Directed Therapy)**: Novel immunomodulation strategies
  - Related to: 4 anchor papers, 3 review papers
  - Position: Advancing therapeutic approach

---

### 3. í•œê³„ì  & ëŒíŒŒêµ¬ (Limitations & Breakthroughs)

#### 3.1 Emerging Concepts

**ìƒˆë¡œìš´ ë°©í–¥ë“¤**:
- Internal medicine approaches: ğŸ†• NEW
- Chemistry-based interventions: ğŸ†• NEW (not in foundational papers)

---

### 4. ë¯¸ë˜ ë°©í–¥ (Future Directions)

[Extracted from recent trends + emerging concepts]
```

---

## êµ¬í˜„ ê³„íš

### Week 1: MVP
- [ ] `concept_framework_builder.py` ê¸°ë³¸ êµ¬í˜„
- [ ] Simple heuristic classification
- [ ] Concept extraction (OpenAlex concepts)
- [ ] Basic clustering (K-means)
- [ ] Framework generation
- [ ] Markdown output

### Week 2: Enhancement
- [ ] Abstract text analysis (if available)
- [ ] Better classification (beyond heuristics)
- [ ] Speaker mapping integration
- [ ] Visualization (optional: network graph)

### Week 3: Testing & Refinement
- [ ] Test on multiple session topics
- [ ] Refine classification rules
- [ ] Optimize clustering parameters
- [ ] Documentation

---

## ì„±ê³µ ì§€í‘œ

1. **Concept Extraction Quality**
   - Top 10 concepts should be meaningful (not too generic)
   - Manual validation: >70% relevance

2. **Classification Accuracy**
   - Papers classified into correct category
   - Manual validation: >60% accuracy (heuristic-based)

3. **Framework Usefulness**
   - Provides clear problem-solution structure
   - Helps understand session organization
   - User survey: >4/5 stars

4. **Speaker Mapping**
   - Speakers correctly positioned in framework
   - Mapping makes sense to domain experts

---

## í•œê³„ì  (ì¸ì •)

1. **No ground truth**: ì •ë‹µì´ ì—†ìŒ (unsupervised)
2. **Heuristic-dependent**: Rule-based â†’ ë„ë©”ì¸ë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
3. **Concept granularity**: OpenAlex conceptsê°€ ë„ˆë¬´ broadí•  ìˆ˜ ìˆìŒ
4. **Abstract availability**: OpenAlexì— abstractê°€ ì—†ëŠ” ê²½ìš° ë§ìŒ

**ì™„í™” ì „ëµ**:
- ì—¬ëŸ¬ heuristic ì¡°í•©
- User feedback ê¸°ë°˜ refinement
- Conference-specific tuning

---

**Version**: Design v1.0
**Status**: Ready for implementation
**Estimated Time**: 2-3 weeks for MVP + testing
